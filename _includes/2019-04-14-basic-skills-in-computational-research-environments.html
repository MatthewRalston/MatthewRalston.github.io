<!--

  ---
author: ralston
title: Basic Skills in Computational Research Environments
description: An early blog post about differences between Data Analysts, Data Scientists, and Data Engineers
date: 2019-04-14 20:31:28 +0400
layout: post
refactor: true
panel_includes:
  - toc
tail_includes:
  - related-posts
  - post-nav
script_includes:
  -comment

categories: [Prose, Meta, Bioinformatics, Opinion, rant, Software]
tags: [meta, prose, bioinformatics, education, beginner, rant, opinion, blog]
permalink: /blog/basic-skills-in-computational-research-environments
pin: true
hidden: false
---
-->

<style>
a {
  color: #000000;
  text-decoration: none;
  border-bottom: none !important;
}

</style>


<img src="/assets/img/realpython_puzzle_pieces.jpg"/>


<h2 id="introduction">Introduction</h2>

<p><span class="hover-image-container"><a href="#">Big data</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/ancient_aliens_big_data.jpg" alt="Hover image"/><span class="image-caption">Growth in data was foretold</span></span></span> is a <span class="hover-image-container"><a href="#">meme</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/big_data_is_like_teenage_sex.jpg" alt="Hover image"/><span class="image-caption">maybe_there_are_no_solutions.jpg</span></span></span>, but different flavors of bioinformaticians can be <span class="hover-video-container"><a clas="video-link" href="#">referred to</a><span class="hover-video-wrapper"><iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/9Ux0eOPanxE?si=_h4uM_bwOZp8mTYO&autoplay=1" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe></span></span> as analysts, data scientists, and data engineers. <span class="hover-image-container"><a href="#">This article</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/im_a_pleb.jpg" alt="Hover image"/><span class="image-caption">no_shame_in_trying.jpg</span></span></span> just brushes the surface of the differences and focuses the conversation on the <span class="hover-image-container"><a href="#">reliance</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/family_guy_teammates.jpg" alt="Hover image"/><span class="image-caption">actually_a_brilliant_strat.jpg</span></span></span> of individual team members on each other for <span class="hover-image-container"><a href="#">hypotheses</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/carl_sagan_nice_hypothesis.jpg" alt="Hover image"/><span class="image-caption">We're made of star stuff. We're the way for the cosmos to know itself...</span></span></span>, <span class="hover-video-container"><a class="video-link" href="#">databases</a><span class="hover-video-wrapper"><iframe width="560" height="315" src="https://www.youtube.com/embed/b2F-DItXtZs?autoplay=1&start=" title="Youtube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe><span class="video-caption">Is MySQL Web Scale?</span></span></span>, <span class="hover-image-container"><a class="video-link" href="#">models</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/zoolander_how_many_abodiginals_do_you_see_modeling.jpg" alt="Hover image"/><span class="image-caption">no_rly_how_many_people_can_do_that.jpg</span></span></span>, <span class="hover-image-container"><a href="#">calculations</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/spongegar_calculator.png" alt="Hover image"/><span class="image-caption">muh_calculation.png</span></span></span>, <span class="hover-image-container"><a href="#">websites</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/geocities_abes_page.gif" alt="Hover image"/><span class="image-caption">quality_hypertext.gif</span></span></span>, <span class="hover-image-container"><a href="#">reports</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/office_space_tps_report.gif" alt="Hover image"/><span class="image-caption">she_went_and_told_Gladys.gif</span></span></span>, and more. When I was in school, it was almost a joke that bioinformaticians who provide alignment, differential expression analyses, and modeling of transcriptomic data often get <span class="hover-image-container"><a href="#">excluded</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/office_space_set_the_building_on_fire.gif" alt="Hover image"/><span class="image-caption">all_i_wanted_was_a_gd_stapler.gif</span></span></span> from <span class="hover-image-container"><a href="#">papers</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/and_then_we_said_wealth_trickles_down.jpg" alt="Hover image"/><span class="image-caption">100% meritocracy</span></span></span> in favor of scientists doing the laboratory work. I dont think the field is mature enough to understand the <span class="hover-image-container"><a href="#">complexity</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/spongebob_as_long_as_we_have_our_bioinformatics.jpg" alt="Hover image"/><span class="image-caption">imagination.jpg</span></span></span> of <span class="hover-video-container"><a class="video-link" href="#">computation</a><span class="hover-video-wrapper"><iframe width="560" height="315" src="https://www.youtube.com/embed/wuxW7u_Wt0E?autoplay=1&start=" title="Youtube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe><span class="image-caption">xXxRoninC0d3r</span></span></span> involved or how <span class="hover-image-container"><a href="#">fortunate</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/how_fortunate_we_are_to_eat.jpg" alt="Hover image"/><span class="image-caption">Number 1 reason: El Diablo burritos in PC</span></span></span> it is that such work is even possible at this stage. By the end of the article, you should have a better understanding of the types of skills that can be useful, the strengths and weaknesses of certain flavors of bioinformaticians (data scientist vs data engineer), and how developing those skills at the expense of others will <span class="hover-image-container"><a href="#">pidgeonhole</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/pidgeonhole_at_least_one_pigeon_has_more_than_one_hole.jpg" alt="Hover image"/><span class="image-caption">quantitative_reasoning.jpg</span></span></span> you into a role where it is <span class="hover-image-container"><a href="#">your responsibility</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/gaslighting_101.jpg" alt="Hover image"/><span class="image-caption">Wait... I'm my only advocate?</span></span></span> to communicate value and preferences to your team.  Bioinformaticians have some balance of software, comp sci, maths/stats, and scientific expertise</p>



<p><span class="hover-image-container"><a href="#">Data science</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/dr_evil_rebranding.jpg" alt="Hover image"/><span class="image-caption">People don&apos;t like statistics</span></span></span> is not new. <span class="hover-image-container"><a href="#">Data science</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/data_science_jargon.jpg" alt="Hover image"/><span class="image-caption">What's with the rebrand</span></span></span> did not invent machine learning or modeling approaches any more than <span class="hover-image-container"><a href="#">Six Sigma</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/picard_facepalm.gif" alt="Hover image"/><span class="image-caption">Black belt btw</span></span></span>  invented statistics. Occassionally you hear something like '<a class="sneaky" href="https://www.fastcompany.com/3063835/microsofts-biological-computing-lab-wants-to-fight-diseases-by-reprogrammin">Microsoft wants to solve biology</a>' or 'AI experts claim they can out-compete the pharma industry' in headlines and it's just... cute. And I'm not even an expert.</p>

<h2 id="a-bit-about-my-background">A bit about my background</h2>
<p>While studying biochemistry I learned some basic analytical chemistry and laboratory methods, but I wanted to move towards biology. I was discouraged at the pace of single-gene analyses in molecular biology given the scope of the systems involved and the degree of heterogeneity in cancer biology. After graduating I joined the Bioinformatics and Computational Biology program at my uni and moved into sequencing data analysis and associated work and I got a few second authorships under the guidance of K and T. The projects were enjoyable and the environment stimulating if not a little disheartening during the anti-science spending policies of the time, but research was still happening, and I was lucky enough to work on microbial transcriptomics data. Eventually I joined a research pharmaceutical firm where I worked until early May of 2019, a chance to practice and improve my software development and see how large the systems facilitating that level of research can really be. Many scientists avoid infrastructure work, sadly. The systems at play in those companies can be very complicated and web technology is a must when it comes to informatics in pharma. Right before I left I developed a talent for benchmarking and modeling the performance of my software which helps me as an individual better communicate value to teams. Okay, thanks for listening. Now let&apos;s talk a bit about skillsets and standards for industry bioinformaticians.</p>




<img src="/assets/img/data_science_vs_data_engineer.png"/>

<h2 id="analysts-data-scientists-and-data-engineers">Analysts, Data Scientists, and Data Engineers</h2>

<p>Every scientist has a <span class="hover-image-container"><a href="#">flavor</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/chloe_all_these_flavors.jpg" alt="Hover image"/><span class="image-caption">Taste all teh flavors</span></span></span> and a role. Bench <span class="hover-image-container"><a href="#">rats</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/chuckie_cheese_bubonic_plague.jpg" alt="Hover image"/><span class="image-caption">cheesy_joke.jpg</span></span></span>, <span class="hover-image-container"><a href="#">desk jockeys</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/head_smasher.gif" alt="Hover image"/><span class="image-caption">amirite_fellow_organics.gif</span></span></span>, <span class="hover-image-container"><a href="#">engineers</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/aoe2_mediterranean_castle.jpg" alt="Hover image"/><span class="image-caption">good_times.jpg</span></span></span>, and more. And each scientist computational or otherwise makes a choice about <span class="hover-image-container"><a href="#">laboratory techniques</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/no_idea_golden_retriever_scientist.jpg" alt="Hover image"/><span class="image-caption">Multiplex != better</span></span></span>, <span class="hover-image-container"><a href="#">statistical skills</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/no_idea_excel_dog.jpg" alt="Hover image"/><span class="image-caption">More details below</span></span></span>, <span class="hover-image-container"><a href="#">computational abilities</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/no_idea_golden_retriever_coder.jpg" alt="Hover image"/><span class="image-caption">More details below</span></span></span>, infrastructure, and reliance on homegrown or third-party tools. In addition, the complexity of the biological systems under investigation requires advanced modeling and simulation techniques in contrast to simpler hypothesis testing. I would gather that most bioinformaticians fall somewhere within the following 3 categories, with strengths and obligations accordingly. <span class="hover-video-container"><a href="#">As you learn skills or specialize in these directions</a><span class="hover-video-wrapper"><iframe width="560" height="315" src="https://www.youtube.com/embed/rTnHZF49is4?autoplay=1&start=" title="Youtube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe><span class="video-caption">Odd. It rings true even more since the pandemic. "A new scapegoat for tough numbers..."</span></span></span>, try to understand the parts of your team that are in the minority.</p>


<img src="/assets/img/scientist_gorilla.png"/>
<h4 id="scientists-and-analysts">Scientists and Analysts</h4>

<p>In my experience, <b>most scientists can do basic <span class="hover-image-container"><a href="#">regression</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/oprah_you_get_a_regression.jpg" alt="Hover image"/><span class="image-caption">FTW actually...</span></span></span> and <span class="hover-image-container"><a href="#">hypothesis</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/joker_retain_the_null_hypothesis_everyone_loses_their_mind.png" alt="Hover image"/><span class="image-caption">negative_results_are_still_results.png</span></span></span> testing in Excel</b>. Armed with educational or professional backgrounds in specialized biological or chemical knowledge, they have good understanding of <span class="hover-image-container"><a href="#">experimental design</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/zoidberg_experimental_design_is_bad_and_you_should_feel_bad.jpg" alt="Hover image"/><span class="image-caption">Douglas C. Montgomery, Gil. Strang, CRC Press McElreath...</span></span></span>, and <span class="hover-image-container"><a href="#">scientific communication</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/zoidberg_communication_skills_are_bad_and_you_should_feel_bad.jpg" alt="Hover image"/><span class="image-caption">Is this a 'meta'?</span></span></span>. <b>However, their weakness in the <span class="hover-image-container"><a href="#">computational side</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/erkle_nerd.gif" alt="Hover image"/><span class="image-caption">Thought they'd be friends...</span></span></span> of the field means they have little understanding of novel <span class="hover-image-container"><a href="#">metrics</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/metric_star_destroyer.png" alt="Hover image"/><span class="image-caption">Foot_pound.png</span></span></span>, <span class="hover-image-container"><a href="#">modeling techniques</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/willie_wonka_regression_is_machine_learning.jpg" alt="Hover image"/><span class="image-caption">Pragmatism > theory</span></span></span>, or the <span class="hover-image-container"><a href="#">costs</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/stallman.jpg" alt="Hover image"/><span class="image-caption">What about ethics?? Rust foundation? PyPI? EFF and FSF?</span></span></span> associated with software design and <span class="hover-image-container"><a href="#">calculations</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/always_sunny_in_philadelphia_the_gang_figures_out_their_aws_bill.jpg" alt="Hover image"/><span class="image-caption">Money_through_obfuscation.webp</span></span></span></b>. One of the benefits of calculations, models, and simulation is the reduced cost of laboratory experimentation through prediction or simulation of results and scenarios that would require considerable experimentation to do otherwise. They are heavily reliant on graphical interfaces, websites, and databases. And <b>they rely heavily on the following groups to build tools, critique third-party infrastructure, clean datasets, or provide models</b> that can be used.</p>


<img src="/assets/img/data_scientist_simple.jpg"/>

<h4 id="data-scientists">Data Scientists</h4>

<p>There are often more <span class="hover-image-container"><a href="#">insights</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/it_was_really_statistics_the_whole_time.jpg" alt="Hover image"/><span class="image-caption">Rebranding_continuted.jpg</span></span></span> to gain from existing datasets and not enough time or <span class="hover-image-container"><a href="#">personnel</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/dilbert_big_data_in_the_cloud.png" alt="Hover image"/><span class="image-caption">This is why we can't have nice things...</span></span></span> to model or suggest future sampling required for improved <span class="hover-image-container"><a href="#">'sensitivity'</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/south_park_were_sorry.gif" alt="Hover image"/><span class="image-caption">me_irl_irl.gif</span></span></span> and <span class="hover-image-container"><a href="#">specificity</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/girl_burning_house_im_not_mad.jpg" alt="Hover image"/><span class="image-caption">the_most_secure_encryption.png</span></span></span> of inferences. <b>This has led to the rise of the data scientist specialization and new curricula designed to provide quantitative and computational skillsets to the next generation of analysts</b>. With a strong background in matrix algebra and calculus, statistics, machine learning, and basic or intermediate software skillsets, data scientists are prepared to interpret larger datasets, perform calculations, and develop professional reports from combinations of new and old data.</p>

<p>They tend to have proficiency in R, Perl, Python, SQL, and shell languages. They are results oriented and make the most of existing infrastructure, not feeling shy to ask or query for datasets. <b>However, their weakness in other pragmatic aspects of programming such as <span class="hover-image-container"><a href="#">web development</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/web_development_essentials.jpg" alt="Hover image"/><span class="image-caption">Basic_skills_means_scope_creep.webp</span></span></span>, <span class="hover-image-container"><a href="#">algorithm performance</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/big_o_notation.jpg" alt="Hover image"/><span class="image-caption">Scalability < sensibility</span></span></span>, or <span class="hover-image-container"><a href="#">systems design</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/aws_haplotyper_system.jpg" alt="Hover image"/><span class="image-caption">Basic haplotyper with scheduler</span></span></span> is not emphasized by most data science curricula</b>. Decisions are often made from their analyses and they have considerable decision making power. But again their job descriptions often focus on analyses and results instead of evaluating existing tools or building new infrastructure to enable others. <b>They rely on existing databases and tools but juniors seldom participate in database or application designs, novel feature engineering problems (typically given to seniors), or improve the efficiency of existing tools</b>.</p>

<img src="/assets/img/data_engineering_simple.jpg"/>

<h4 id="data-engineer">Data Engineer</h4>

<p>The final category is also newer in its formalization, especially with the rise of larger <span class="hover-image-container"><a href="#">datasets</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/bunny_labeling_ur_dataset.jpg" alt="Hover image"/><span class="image-caption">Bunnies and biology.. good reads actually...</span></span></span>, <span class="hover-image-container"><a href="#">databases</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/world_meme_database.png" alt="Hover image"/><span class="image-caption">Meme enjoyer, novice collector</span></span></span>, or mixed numerical and document storage or abstract representations. <b>Data engineers have rich software engineering and computer science abilities that lets them build critical <span class="hover-image-container"><a href="#">infrastructure</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/infrastructure_means_build_your_way_out_of_a_job.png" alt="Hover image"/><span class="image-caption">Not working? Dont fix it...</span></span></span> for others with a focus on stability, usability, and efficiency</b>. <span class="hover-image-container"><a href="#">Pre-computating</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/inception_we_need_to_go_deeper.png" alt="Hover image"/><span class="image-caption">What if we used 100% of our grad students?</span></span></span> all the metrics, <span class="hover-image-container"><a href="#">annotation</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/fry_not_sure_if_curation_is_key.jpg" alt="Hover image"/><span class="image-caption">Not sure if there is metadata quality here...</span></span></span> of datasets, and automation may be required for databases and applications in their wheelhouse. Enterprise software is often expensive to license and data engineers make a team responsive to the teams computational needs in a way that scientists and data scientists often cannot. However, I would say that these teammates, the data engineers, were an obvious minority in the teams Ive worked in. Their weakness is certainly a basic or non-specific background in the applied area and most companies do not support the growth of data engineers towards the scientific area. That said, <b>they are invaluable teammates and can provide scripts, REST-APIs, databases, automated systems, web applications, and even some <span class="hover-video-container"><a href="#">high-performance computing</a><span class="hover-video-wrapper"><iframe class="youtube-frame" width="560" height="315" src="https://www.youtube.com/embed/KEkrWRHCDQU?autoplay=1&start=" title="Youtube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe><span class="video-caption">test</span></span></span> needs.</b></p>



<p>From basic computational skills to rather advanced, the needs of analytics in modern scientific fields cannot be overstated. <b>Working in a team can be quite complicated and challenging, especially with the limited business, project management, and philosophical training that most S.T.E.M. curricula provide</b>. Take for example a group I was in: the bulk of the deliverables were produced by theoretically focused scientists who were adept at running simulations in GUIs but only vaguely participated in infrastructure design, construction, or maintenance.</p>

<p>Producing deliverables to other groups is our most important role, from the perspective of those outside ours. However, the theoretical scientists efficiencies can be enhanced with the appropriate infrastructure or selection from a diverse range of modeling tools. <b>The divide between the engineers and theoretical scientists is natural in these groups but reinforces boundaries between those with visibility to the rest of the company vs. those that enable the group through software and algorithm performance</b>.</p>

<h2 id="difference-between-software-dev-and-comp-sci">Difference between software dev and comp sci?</h2>

<h4 id="software-dev-and-project-management">Software dev and project management</h4>

<p>Software development or software engineering is a discipline that I would argue is very humanistic, highly in flux, and largely driven by ecommerce. Software engineers build <span class="hover-image-container"><a href="#">calculators</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/spongegar_calculator.png" alt="Hover image"/><span class="image-caption">gimme_da_answer.png</span></span></span>, <span class="hover-image-container"><a href="#">databases</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/hackerman_databases.png" alt="Hover image"/><span class="image-caption">Jesus Christ..., its Jason Bourne</span></span></span>, <span class="hover-image-container"><a href="#">applications</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/drake_website_with_scratch.jpg" alt="Hover image"/><span class="image-caption">nah_but_scheme_was_tite.png</span></span></span>, and <span class="hover-image-container"><a href="#">software systems</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/packet_sniffing_diagram.jpg" alt="Hover image"/><span class="image-caption">x1337hax0r322</span></span></span> that enable other members of their organization. Software engineering tools focus on <span class="hover-image-container"><a href="#">application frameworks</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/lamp.jpg" alt="Hover image"/><span class="image-caption">totally_modern_meme.webp</span></span></span>, project management skills, and interface design to make the product as <span class="hover-image-container"><a href="#">mature and useful</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/hawaii_missile_alert.gif" alt="Hover image"/><span class="image-caption">hawaii_missile_alert.gif</span></span></span> for the end-user while maintainable for other software developers. Software development skills include version control systems, or <span class="hover-video-container"><a href="#">VCS</a><span class="hover-video-wrapper"><iframe class="youtube-frame" width="560" height="315" src="https://www.youtube.com/embed/CDeG4S-mJts?autoplay=1&start=" title="Youtube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe><span class="video-caption">Hulter tries git</span></span></span>. Arguably the most popular version control system at the moment is <span class="hover-image-container"><a href="#">git</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/i_prefer_the_real_version_control.png" alt="Hover image"/><span class="image-caption">I prefer final_project_LAST_2019-01-22.tar.gz</span></span></span>.</p>

<p>Other useful skills for software developers to have (and maintain) include software testing strategies like the so called <span class="hover-image-container"><a href="#">Behavior Driven Development</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/rspec.gif" alt="Hover image"/><span class="image-caption">If you want..</span></span></span> or BDD, and its older cousin Test Driven Development or <span class="hover-video-container"><a href="#">TDD</a><span class="hover-video-wrapper"><iframe class="youtube-frame" width="560" height="315" src="https://www.youtube.com/embed/fh1_jiKfzLw?autoplay=1&start=" title="Youtube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe><span class="video-caption">Holtre tries unit testing.</span></span></span>. In fact, the whole world of software development has a new era feel ever since Web2 made large centralized software development include features of rapid iteration and testing. The world of DevOps isnt worth getting into. No seriously, dont do it. DevOps teams dont even do it. However, interesting features for larger software development organizations include practices such as <span class="hover-image-container"><a href="#">continuous integration (CI)</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/software_project_management.jpg" alt="Hover image"/><span class="image-caption">halfway_awful_devops_graphic.jpg</span></span></span>, <span class="hover-image-container"><a href="#">package management</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/expanding_brain_package_management.png" alt="Hover image"/><span class="image-caption">shameless_technical_opinion.png</span></span></span>, <span class="hover-image-container"><a href="#">web design</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/dr_evil_on_web_design.jpg" alt="Hover image"/><span class="image-caption">do_people_rly_enjoy_this_stuff.webp</span></span></span>, and user interfaces or <span class="hover-image-container"><a href="#">UI</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/hawaii_missile_alert2.gif" alt="Hover image"/><span class="image-caption">okay_not_as_easy_as_i_thought.gif</span></span></span>.</p>

<p>There is an entire rabbit-hole of software engineering skills to learn the terminology, consider the use-case, and drop it like a hot potato. Consider <span class="hover-image-container"><a href="#">software systems</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/web_app_design.jpg" alt="Hover image"/><span class="image-caption">test</span></span></span> architecture, <span class="hover-image-container"><a href="#">automaton paradigms</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/conan_cron.jpg" alt="Hover image"/><span class="image-caption">something something bare metal, and iron and wine?</span></span></span> for instance. When automating your paradigms, youll want to ensure your code is tested, because observing murphys law...you know that whatever can happen will happen, often for the worse. For this reason, <span class="hover-video-container"><a href="#">faulty</a><span class="hover-video-wrapper"><iframe class="youtube-frame" width="560" height="315" src="https://www.youtube.com/embed/eE7Bfw9lFfs?autoplay=1&start=" title="Youtube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe><span class="video-caption">Dungeon raid... but also.. this was long before Linus had issues with one of his employees.</span></span></span> software will need to be redacted and entire studies may be removed, crippling a researchers career. Understanding application fault <span class="hover-video-container"><a href="#">tolerance</a><span class="hover-video-wrapper"><iframe class="youtube-frame" width="560" height="315" src="https://www.youtube.com/embed/1P8ZecG9iOI?autoplay=1&start=" title="Youtube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe><span class="video-caption">I need to touch grass.</span></span></span>
  allows us to build reliable applications that are more resilient to subsystem failures, logging the errors rather than crashing the server, and other system quality considerations.</p>

<p>But then again, on the simpler side... pre-deployment? Theres a ton of skills to master there too. User interface (<span class="hover-image-container"><a href="#">UI</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/hawaii_missile3.gif" alt="Hover image"/><span class="image-caption">Can it be that it was all so simple then?</span></span></span>) is the tip of the ice berg when building products that colleagues, customers, professors, and other students will want to use.</p>

<p>Like many professions, time management and documentation are crucial skills for describing work that has been done or is required for meeting milestones, deadlines, and budgetary guidelines. Project management skills include <span class="hover-image-container"><a href="#">documentation</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/sphinx-doc.el_automatic_docstrings.gif" alt="Hover image"/><span class="image-caption">handy Sphinx docstrings into ReadTheDocs for Python code</span></span></span>, kanban, Github, Atlassian Confluence and Jira, and more traditional Gant charting, minimum-viable product (MVP), budgeting, and cost projection skills.</p>

<p><b>It definitely feels like project management courses should be part of every graduate engineering proram</b>, even if the project-focus teaching style (problem sets, end-of-course projects) is present in addition to a thesis/dissertation. Theres no discussion of common business, budget, and timeline questions like &quot;here&apos;s the questions employers will ask when you&apos;re overbudget or late,&quot; or &quot;here&apos;s the things you should routinely do to communicate value for a project of this size,&quot; or &quot;here&apos;s how you can recruit coworkers and delegate properly so that you don&apos;t become overwhelmed.&quot;</p>

<!-- spellchecked -->

<h4 id="computer-science-math-and-natural-science">Computer science, math, and natural science</h4>

<p>If <b>software development is like the business side of bioinformatics</b>... communicating value, timelines, budgets, stability, usability, maintainability... then <b>computer science is a logical foundation that provides value to calculations, <span class="hover-image-container"><a href="#">pipelines</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/jumanji_what_year_is_it_keystone_pipeline.png" alt="Hover image"/><span class="image-caption">Did I miss the requirement to feel?</span></span></span>, models, or applications</b>. Computer science certainly emphasizes algorithmic performance (<span class="hover-image-container"><a href="#">space</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/linus_leds_dont_make_memory_better.gif" alt="Hover image"/><span class="image-caption">space_issues_are_common_in_bioinf.svg</span></span></span> and <span class="hover-image-container"><a href="#">time</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/sorting_algorithm_comparison.gif" alt="Hover image"/><span class="image-caption">interesting_sort_comparisons.gif</span></span></span>). I can&apos; undersell that enough here; these are incredibly important first principles for compsci students including skills such as big-O notation, <span class="hover-image-container"><a href="#">high-performance computing</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/futurama_fry_3020_make_cola_great_again.jpg" alt="Hover image"/><span class="image-caption">...test</span></span></span> (HPC), <span class="hover-image-container"><a href="#">compiled</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/the_girl_you_like_programming_languages.jpg" alt="Hover image"/><span class="image-caption">flavors.jpg</span></span></span> <span class="hover-image-container"><a href="#">languages</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/i_prefer_the_real_beginner_programming_language.jpg" alt="Hover image"/><span class="image-caption">best_childhood.jpg</span></span></span>, <span class="hover-image-container"><a href="#">parallelization</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/sleeping_processors.png" alt="Hover image"/><span class="image-caption">always_a_bottleneck.jpg</span></span></span> and <span class="hover-image-container"><a href="#">concurrency</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/doggo_feeding_concurrently.png" alt="Hover image"/><span class="image-caption">can_we_get_some_doggone_performance_gains.webp</span></span></span>, <span class="hover-image-container"><a href="#">floating point accuracy</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/javascript_addition_accuracy.png" alt="Hover image"/><span class="image-caption">check out 'wat' bby Gary Bernhardt on YouTube</span></span></span>, <span class="hover-image-container"><a href="#">Occam&apos;s razor</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/occams_razor_kids_homework.jpg" alt="Hover image"/><span class="image-caption">arguably_doing_it_right.png</span></span></span>, and engineering assumptions.</p>




<p>But the discipline has a wide variety of applied areas that work on various data types from primitive (<span class="hover-image-container"><a href="#">float</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/8bit_kirby.gif" alt="Hover image"/><span class="image-caption">a decimal is a mantissa and an exponent</span></span></span>, <span class="hover-image-container"><a href="#">int</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/8bit_rubick.gif" alt="Hover image"/><span class="image-caption">an integer can have 8, 16, 32, or 64 bits of precision</span></span></span>, <span class="hover-image-container"><a href="#">string</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/8bit_spiderman.gif" alt="Hover image"/><span class="image-caption">a list of ASCII characters. Words &apos;n stuff...</span></span></span>, <span class="hover-image-container"><a href="#">array</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/pooh_matrix_indices_start_at_1.png" alt="Hover image"/><span class="image-caption">Rebuttal</span></span></span>, <span class="hover-image-container"><a href="#">hashmap</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/scooby_doo_bigtable_is_hashmap.jpg" alt="Hover image"/><span class="image-caption">Big data hadoops in the cloud at web-scale</span></span></span>) to complex (nested structures, document storage, object-class hierarchies, pickled objects), as well as data location (memory, cache, in-memory cache, cloud, object storage, database, filesystem, compression). Computer science and mathematics allows researchers to derive the <em>right</em> metric for a model to provide better predictive or inferential power. <b>Interdisciplinary science education cannot be expected to adequately cover the diversity of programming paradigms, languages, and frameworks available nor the historical, current, and modern algorithms or modeling techniques used in the field</b>. My program provided an overview of python, fasta parsing, alignment algorithms, web tools, and database technology to make room for advanced topics in biology. <b>Most bioinformaticians-in-training could benefit from workshops on benchmarking, big-O complexity, parameter sweeps, and similar metrics that can help you quantify the value of your implementations</b>.</p>


<h2 id="skills-recommended-for-a-balanced-skillset">Skills recommended for a balanced skillset?</h2>


<p>Again, this is not a curriculum or even a suggestion for a particular bioinformatics course&apos;s focus. But I would say that there are some considerations every bioinformatician makes when deciding which paradigm/language/framework to invest in and this is my best overview of fundamentals that are expected from entry-level bioinformatics developers.</p>

<h4 id="data-formats-data-structures-and-databases">Data formats, data structures, and databases</h4>

<p><em>Almost all data that we work with is <span class="hover-image-container"><a href="#">ASCII</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/ascii_cat.jpg" alt="Hover image"/><span class="image-caption">un gato</span></span></span>,</em> from simple <span class="hover-image-container"><a href="#">.tsv</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/when_you_make_memes_in_excel_instead_of_paint.jpg" alt="Hover image"/><span class="image-caption">ms paint expanding brain</span></span></span>, <span class="hover-video-container"><a href="#">fastas</a><span class="hover-video-wrapper"><iframe class="youtube-frame" width="560" height="315" src="https://www.youtube.com/embed/SbjRfpUgrlM?autoplay=1&start=" title="Youtube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe><span class="video-caption">thx, good fun.</span></span></span> and fastqs to <span class="hover-image-container"><a href="#">abstract</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/circos_cancer_cell.png" alt="Hover image"/><span class="image-caption">It&apos;s technically XML.</span></span></span> and extensible formats like (a)cyclic network formats, PDBs, 2D/3D chemical structures, or tree structures. Knowlede of compression and encryption is also essential for working with clinical and compressed large datasets. For reference, the 1000 genomes project sequenced over <a href="https://www.nature.com/articles/nmeth.1974">260 terabytes</a> and the Broad Institute has sequenced over <a href="https://www.broadinstitute.org/news/broad-institute-sequences-its-100000th-whole-human-genome-national-dna-day">70 petabytes</a> compared with the size of the Netflix library of <a href="https://gizmodo.com/how-netflix-makes-3-14-petabytes-of-video-feel-like-it-498566450">3.14 petabytes</a>. Other data furmats are emerging that are loosely constrained (<span class="hover-image-container"><a href="#">JSON</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/xml_vs_json1.png" alt="Hover image"/><span class="image-caption">meh, kind of cool</span></span></span>) and are the basis for more complex data structures or databases. Validating and specifying complex structures is an ongoing problem and familiarity with <a href="https://json-schema.org/">json-schema</a> is a plus. Or minus...</p>

<p>Database technologies like MariaDB(formerly MySQL), PostgreSQL, and MongoDB are mainstays of enterprise data systems and web applications. A limited understanding of the entity-relationship model and normalizations isn&apos;t going to lose you the job, but it will make you a more effective web developer and data scientist.</p>

<p><b>But the most challenging aspect of modern data-driven fields is the tradeoff between the <em>minimal amount of data for a complete record</em> and the <em>maximum amount of flexibility</em> to anticipate the community&apos;s uses</b>. I&apos;ll use the example of 2D/3D chemical structures to illustrate.</p>

<p><em>SMILES is a landmark cheminformatics format, made in the 1980s, for representing the network of a molecule&apos;s atoms in an easy-to-read format</em>, superseded recently by the less easy-to-read IUPAC format InChI with better normalization and querying capabilities. <em>The alternatives were hard for humans to read without the aid of GUIs, poorly extensible, and had a maximum record size</em> of 999 atoms due to the Fortran record format of the original implementation. This format is still relevant today because of how easy it is for computational scientists to read or quickly understand what a molecule&apos;s composition is at the command-line. Fasta is a similarly <em>simple</em> format but is almost <b>impossible</b> to understand by reading long and low-dimensional nucleotide sequences.</p>

<p>Crystallographers required a larger and more extensible format for larger chemical structures and biomolecules and thus the PDB format was born. <em>The modern PDB format is not human readable and requires the aid of a GUI to visualize but it supports metadata and other extensions</em>. But with all of the <a href="https://en.wikipedia.org/wiki/Chemical_file_format#The_Chemical_MIME_Project">available formats</a> for cheminformatics, one has to wonder why efforts to parse and perform calculations on chemical formats are so disjointed, adding to the issue the near-infinite scope of chemical structures, macromolecules, and issues of post-translational modification, chemical protection, and cleavage sites. In summary, <b>many different ecosystems of formats, parsers, and convenience functions get created with sometimes different goals: <em>easy-to-read at the command line</em> vs <em>flexible and extensible formats</em> for more complex data structures</b>. This dichotomy is very relevant for bioinformatics.</p>

<!-- EDIT HERE -->

<p>So what makes a file format and supporting software 'good'? For example, <b>BAM isn&apos;t particularly earth-shattering in its computational basis</b>. It&apos;s a tsv format with a compression layer that shows alignment, sequence, quality, and mapping statistics, generated from much simpler fastq files. The implementations Picard and SAMtools are both high-quality with differing opinions on single-record and whole-sample validity. <b>In my opinion, it&apos;s a really good <em>implementation</em></b> from an efficiency and usability perspective, with standard support for <em>compression and indexing, a good test suite, and community support</em>. What is amazing about it is the quality of the specification. As a result there is excellent adoption rate, and consistent implementation.</p>

<p>Data formats are essential for bioinformaticians, but <em>many formats have limited community support, are redundant with other formats, or don&apos;t anticipate the community&apos;s needs</em>. And <b>most bioinformatics curricula do not include a critique or survey of existing formats, ideas for consolidation, or discussion of differences in formats</b> as essential for NGS technology as SAM/BAM. These are skills and perspectives that <span class="hover-video-container"><a href="#">experience</a><span class="hover-video-wrapper"><iframe class="youtube-frame" width="560" height="315" src="https://www.youtube.com/embed/WqCpWu8tgRw?autoplay=1&start=" title="Youtube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe><span class="video-caption">test</span></span></span> <em>can</em> remedy, but the nature of those formats and the depence of software systems on their consistency should be taken in to account when building &apos;futureproof&apos; systems of automated processing, warehousing, annotation, and even analysis. All of those systems are then built with languages and programming paradigms that are also evolving and need consideration during each bioinformatician&apos;s training, and advice on these subjects is typically neglected.</p>


<h4 id="languages-paradigms-and-problem-solving" >Languages, paradigms, and problem solving</h4>

<p>I&apos;d like to leave the topic of data formats and databases to talk for a moment about the programming languages that we use to build our tools and systems, and the paradigms that influence our problem solving strategies. Many bioinformaticians are first exposed to easy-to-use interpreted languages like Python or Perl, with little attention given to shell proficiency, operating system tools, compiled languages, and the nature of <span class="hover-image-container"><a href="#">debugging</a><span class="hover-image-wrapper"><img class="hover-image" src="/assets/img/The-Ultimate-Guide-to-Python-Type-Checking_Watermarked.webp" alt="Hover image"/><span class="image-caption">Types, Enums, Function signatures, Errors, Results, Options...</span></span></span> single tools or whole software systems. <b>Advanced programming isn&apos;t taught often to graduate bioinf. students</b> and novices make numerous choices novices without much top-down support about why conventions, dichotomies, or pluralities exist.</p>

<p>These days, memory issues are about as common as computational efficiency with the datasets we work with and can&apos;t be solved by simply switching to the steeper learning curve but better performance of compiled languages. Consequently, we often throw compute power and parallelization at most scientific tasks instead of switching to compiled languages. <em>Type-checking and format validation is almost an afterthought for beginner bioinformaticians but is the most common errors beginners face</em>. Rather than make a suggestion here, I&apos;ll just say that I&apos;ve tried to balance my dialects with Python, R, shell, Ruby, and some novice level Haskell. I&apos;m watching the Julia project with anticipation, but I doubt that I&apos;ll find much acceptance in industry. <em>But in summary, static typing and type-checking is often a better solution than using a purely dynamic coding style or using more verbose compiled languages</em>.</p>

<p>I&apos;d claim from my experience that object-oriented programming isn&apos;t a <em>bona-fide</em> paradigm but instead is a construct for complex data-structures and the resulting encapsulation (part of the definition) with some aspects of declarative or imperative thrown in. <b>I would suggest that most new bioinformaticians look at functional programming and type-classes instead of learning object-oriented programming in depth</b>, trying not to glaze over at the abstract algebra involved to understand the merits of compiled languages and static typing, and how scientific such languages can be. Eliminating type errors reduces debug time, iteration time, and gets developers to the qualitative issues of their software much faster.</p>

<p><b>Every bioinformatician needs to know two paradigms: functional/procedural and event-loop</b>. I&apos;ll go out on a limb and suggest that functional and procedural programming are simply distant cousins and should be treated as one overarching paradigm. <em>Functional implementations are easy to understand with our mathematical backgrounds</em>. Sometimes procedural implementations and familiarity with language internals/optimization makes code run faster but look less pleasing to understand. The only other programming paradigm in my understanding is event-loop languages like Javascript or Erlang. Concurrency <em>can</em> lead to considerable speedup in web applications or other systems that rely on external networked calls, but Javascript is a language of user-interfaces and web development and can be essential for data scientists looking to present tables, interactive graphics, or mature interfaces to their users.</p>

<p>The language ecosystem is the final under-described consideration that informs beginners and novices of language choice and influences intermediate users to switch to modern, marketable, and maintainable tools. Package management and security are important factors for enterprise systems, but more important are testing and documentation standards or heuristics/shortcuts taken by standard library algorithms. You&apos;ll know what I mean when you encounter a shortcut in the standard library that is not correct, but correct &apos;enough&apos; for web developers and ecommerce. In summary, <b>choose a language with a strong standard library, documentation, conventions for package structure and installation process, and with a strong bioinformatics ecosystem.</b></p>

<p>Rather than focus on problem solving paradigms directly, I spent the time talking about type-classes, two major programming paradigms, and ecosystem considerations when you choose which languages to develop skills with. Each problem has multiple approaches, where parallelization and concurrency can dramatically effect system/calculation performance. Some problems have redundant calculation, or frequently &apos;visited&apos; substructures in a larger database, format, etc. where cache or index support should be provided. These issues affect both larger software systems with elaborate graphical user interfaces (GUIs) and simple command-line tools (I like to call them calculators) that are mainstays of the bioinformatics community.</p>

<h4 id="user-interfaces">User interfaces</h4>

<p>I&apos;ll focus next on two types of user interfaces that developers should be familiar with consuming or producing for their customers, collaborators, end-users, or organization. The first thing to consume or build is of course the command-line interface. I&apos;ll describe an opinion here about an ideal Python-based calculator with subcommands. It should have no suffix (<code>mycommand</code> instead of <code>mycommand.py</code>) and a shebang should be present in the entry point. It should use STDIN/STDOUT preferably over <code>--infile</code> or similar. It should make use of standard argument parsing libraries like argparse where possible to make the code maintainable and extensable and built in support for <code>-h, --help</code> on the base command and all subcommands. <b><code>git</code> and the <code>aws-cli</code> are good examples of mature hierarchial utility command interfaces</b>. A <code>Makefile</code> is a great entry point for auto-documentation, installation, and testing.</p>

<p><em>If your project is Pythonic, your package should have both a &apos;requirements.txt&apos; and a &apos;setup.py&apos; (which could reference the former) to facilitate the installation into the appropriate locations in the user&apos;s environment</em>. Tests should be written (famous last words, I know) to show the stability of the code to different function inputs, expected errors, and interactions between modules/classes. Acceptance tests should be written to show that the CLI responds to input in the right way and produces correct calculations, conversions, or other outputs under various (un)expected situations. Test datasets aren&apos;t always easy to think of, but your code should handle good and bad quality data as you expect, not throw cryptic errors that reflect what you consider to be invalid. Finally, your repository should follow good <code>git</code> practices and you should branch, rebase, and squash according to what most would consider to be best practices. And to top it off, <em>you should let a continuous integration server like Jenkins or Travis-CI run your tests for you!</em> This is just my opinion of what a usable tool could look like to get good acceptance and support from the users.</p>

<p>But in addition, I think that <em>most command-line tools should also have a API/SDK that makes functions/classes available to users who want to integrate it into their codebase</em>. System calls are ugly. It looks cleaner and it&apos;s usually easier to test if you spin off the logic of your calculations into modules/classes and then call these as needed for your subcommand. No one wants to maintain or debug a 2k+ line script with a monolithic &apos;main&apos; function. It&apos;s very easy to have a module directory, &apos;bin&apos;, &apos;docs&apos;, &apos;test&apos;, and &apos;test/data&apos; directories to make a complete CLI tool.</p>

<p>And then there is the REST-API. <em>REST-APIs are mainstays of modern software system architectures and web applications and ultimately provide the developer with a larger audience</em>. They can contain the logic of a web application that can be used by scientists who might not be comfortable at the command-line, by data scientists who want broad access to available data, or for command-line interfaces that send/receive messages or data to the database. LDAP and authentication can come in to play for enterprise systems. 500 response codes are unacceptable: either the request was invalid or the server didn&apos;t find/respond in a way that produced a result... but something should always be returned, even an empty data structure. There are plenty of HTTP response codes that can tell the web page, CLI, or other component of the system why the request didn&apos;t produce a result. <em>Many people like to use a reponse JSON object that looks roughly like the structure below</em>.  I&apos;m still a beginner/intermediate software developer and some software systems can be rather complex, but <b>an understanding of REST-APIs is a good foundation for bioinformaticians seeking to access databases without server-side access, to expose their calculators to a broader audience, or to develop software systems that have considerable value for their organization or audience</b>.</p>

<pre>
{
  success: True,
  data: [...],
  message: "this tells you what was done or what errors were produced"
}
</pre>

<p>Interface is a consequence of any calculation that you find useful and you&apos;ll find some you like, some you don&apos;t, and a whole bunch in between. Rather than describe any javascript or MVC framework you should go learn, I just decided to keep it non-commital and say that the choice of interface is important when you&apos;re deciding the scope of a project and timelines. Your interests in UI will adapt to the needs of your audience (e.g. a few dozen scientists) and the skills of your collaborators (e.g. half a dozen computational scientists).</p>


<h4 id="devops-sysadmin-and-linux-fundamentals">DevOps, SysAdmin, and Linux fundamentals</h4>

<p>The rise of Amazon&apos;s AWS platform has changed the game slightly for developers seeking speicalized hardware or burst capabilities. <b>Developers are being put closer to budgets and efficiencies of their own software</b>. In addition to Linux fundamentals (below), developers are often expected to have a basic understanding of the resources and cost savings available to them with cloud plaforms like Google, AWS, RedHat, and other cloud providers. I won&apos;t go in to extensive detail about the automation and systems tools available on those platforms at this stage, but I&apos;d like to reinforce that <em>the ecosystem and tools available to launch, update, and maintain software system components in different location has matured substantially and the traditional sysadmin roles are changing, as are expectations about top-tier developers</em>.</p>

<h5 id="linux-fundamentals">Linux fundamentals</h5>
<ul>
    <li><code>sed, awk, grep</code></li>
    <li><code>parallel</code></li>
    <li><code>cron, systemd timers</code></li>
    <li><code>systemd, initd</code></li>
    <li><code>/dev, /etc, /mnt, $TMPDIR</code></li>
    <li><code>nfs</code></li>
    <li><code>PBS, SGE/UGE, torque, SLURM</code></li>
    <li><code>httpd, nginx</code></li>
    <li><code>tmux</code></li>
    <li><code>nvim</code></li>
</ul>

<p>There are plenty of manuals and tutorials available for these topics so rather than reiterate here, skip to the next part if you have a basic understanding of what these tools do.</p>


<p><code>sed</code> is a stream editor that edits each line of a piped stream or file according to a regular expression. Need to replace a string in your file/stream? Need to delete quotes? How about remove trailing whitespace or text from a column? These pretty common tasks can be done non-interactively as part of a shell-script or pipeline. If your dataset is too large to fit in memory and edit with <code>emacs</code>, <code>nvim</code>, or something similar, go ahead and use sed to perform subsequent edits using the power of regular expressions.</p>

<p><code>awk</code> is an older stream processing language that can do remarkable things, similar to perl one-liners. However, our knowledge of scripting basics often makes it easier to create a one-off Python/Perl script that provides the same functionality and doesn&apos;t require learning a whole new language (it&apos;s technically Turing-complete). Occassionally you can&apos;t do a stream reformating operation with sed, need to skip lines or similar, rearrange columns or something and <code>awk</code> will be a better fit.</p>

<p><code>grep</code> is another regular expression tool that can filter or locate lines in a file matching the expression. Filtering and finding text in a file is pretty common; search features are built into everything these days. Do it on the fly, non-interactive as a part of your pipeline or script, filter log files for certain warnings or errors. It&apos;s a pretty easy to use tool and is a great segue to <code>sed</code></p>

<p><code>parallel</code> is an optional tool in most Linux distros. It provides simple and performant parallelization of shell-functions, scripts, or simple commands. Want to build easy parallelization into your pipeline or processing? Use something like <code>parallel &apos;program -k {1} -i {2} {3}&apos; ::: $(seq 6 12) ::: $(seq 1000 5000) ::: $(ls /path/to/*.fastq.gz)</code> for a parameter sweep over a range of input fastqs and parameter values (<code>k, i</code>). It&apos;s a great tool for production workflows and parameter sweeps during algorithm development, especially if it&apos;s too complicated to hardcode parallelization in your script, or you just want to do the same thing with different parameter values (a sweep) or across a number of input files.</p>

<p><code>cron</code> is a tool for chronologically-based execution of certain programs (every day at 12am) and is a good tool for building software systems. Update a database, load new data, process that night&apos;s dataset, or create system backups. The primary command-line tool is called <code>crontab</code> and is included in most Linux distros. There is a specific columnar syntax to use when specifying when and how often a command should be run. Systemd timers are a modern replacement for the traditional Linux cron.</p>

<p><code>systemd</code> is the replacement of the traditional process hierarchy in Linux (<code>initd</code>). This is an OS system that is launched early during the boot process to launch other daemons, mount hard drives, connect to the network, launch the firewall, etc. The original process launched in Linux has a process id (<code>pid</code>) = 1, and is usually owned by root. The init process can launch processes as other users for the session to use. <code>systemd</code> is a more advanced process management tool that would ultimately start your Apache <code>httpd</code> server and your web application or ensure automatic startup of those systems after system reboots. Some Linux servers might be on 24/7, might not be rebooted often if ever, or you might not have root permissions to edit system configurations... but you could be asked by a manager to configure your database and application to automatically launch and be fully automated by the system.</p>

<p><code>/etc</code> and similar system directories have unique roles in the operating system. <code>etc</code> typically stores package and application-specific configuration files (ports, environment variables, etc.). <code>/tmp</code> is a very important directory for HPC, since many applications write intermediate files to <code>/tmp</code> if no environmental variable <code>$TMPDIR</code> is set in the user&apos;s profile or in the script. This directory may only have a few gigabytes allocated and is mostly meant for operating system temporary files, not intermediate files of large genomic pipelines. You may need to modify the variable to <code>/scratch</code> or your systems mount point for larger temporary data to be written, which may be automatically wiped out that night! Pay attention to your system administrators, since filling that directory can be catastrophic for the node if the operating system can&apos;t write small temporary files during its uptime. I&apos;ll omit a description of <code>/mnt</code>, <code>/proc</code>, <code>/dev</code> at this time. <code>/usr</code> and <code>/usr/local</code> may contain compiled or shared C++ object files or headers, and are generally the target during source installation (<code>./configure && make && sudo make install</code>), and you probably won&apos;t need to edit anything in this directory. But if you want to install software for others to use on the node, the destination is typically <code>/usr/local/bin</code> instead of <code>/usr/bin</code> or <code>/bin</code>, which are install locations for operating system packages and other system-wide tools or binaries.</p>

<p><code>nfs</code> is a more advanced topic and most of us don&apos;t need to manage storage or shared access at the junior level. It&aposls worth noting however, that large genomic analyses shouldn&apos;t be run in your <code>$HOME</code> directory. Intermediate files should be written to the node&apos;s &apos;ephemeral&apos; storage (like <code>/scratch</code> or <code>/data</code>) and final outputs or logs should be moved elsewhere before the directory is cleaned up. Don&apos;t hammer the NFS server with small mergesort files (<code>samtools sort</code>) or repeated writing to a log file.</p>

<p>Schedulers or grid-engines are part of high-performance computing clusters (cluster computing) and you might have access to one if your institution is supporting one. Your analysis or pipeline might be submitted to the grid, you might have limits for the number of simultaneous jobs, storage limits, and similar limits to be available when requesting one or more processors from one or more &apos;compute nodes&apos; in the cluster. Please don&apos;t reserve multiple cores when the pipeline or tool doesn&apos;t support parallelization or you haven&apos;t configured the option in the tool (<code>bowtie -p 8</code>). Be aware of others you are sharing the calculation power with and plan your processing, pipelines, or parameter sweeps accordingly. If you need more power than available, talk to your advisor about cloud capabilities. I&apos;m running 4 nodes in AWS for about $0.10 per hour. It&apos;s easier than you think!</p>

<p><code>httpd</code> is the Apache server daemon and manages HTTP requests to different websites (static or otherwise) on a usually dedicated web server. If you want to host files or datasets, a shared drive or ftp server might be a better solution. Apache is an older and highly-customizable web server, but is often less performant for high-volume requests. <code>nginx</code> is a concurrent, round-robin web server that is a better bet if you&apos;re expecting higher volume of traffic (100+ sessions) for your web application.</p>

<p><code>tmux</code> is a terminal multiplexer, similar to <code>screen</code>. Imagine you want to connect to a server, and your pipeline is still running when you have to leave for the night! Do you leave your laptop open and vulnerable in your lab? Do you have to awkwardly take the laptop home in your car? What if the battery runs out? What if Windows or OSX decides to automatically update and reboot your machine? What if you want to distro hop or boot up Windows for a Skype session or gaming? <code>tmux</code> is a session that stays open on the server you&apos;ve connected to. ssh into the machine, launch a session, disconnect, launch another, disconnect, check status, disconnect, go home. When you reconnect to the session, all your windows and tabs, editors, pipeliens will still be running and in the state you left them. Check it out!</p>

<h4 id="statistics-and-data-science">Statistics and Data Science</h4>

<p>While we discussed briefly the spectrum of computational skills, experience, and specialization in teams above, I&apos;ll mention that data science and statistical knowledge is a main component of enterprise bioinformatics (and any other informatics position, for that matter). It&apos;s worth noting a few trends or issues that nearly every bioinformatician will face in industry.</p>

<p><b>Literate programming is becoming a strong component of condensed and reproducible research reporting and communications</b>. Literate programming has many flavors but R-Markdown, iPython/Jupyter, and <code>org-mode</code> come to mind readily as efforts to make descriptions of analyses clear, concise, and reproducible. <a href="https://www.dominodatalab.com/">Domino</a> is an enterprise-level reproducibility platform that merges <code>git</code> and AWS platforms to create highly reproducible calculations, RStudio or Jupyter sessions, and other analyses to version control datasets and deployment to cloud platforms. Without being excessively negative, <em>I think the existence of Domino highlights a reproducibility problem within our industry, where developers leave a company, and the scripts or one-off analyses cannot be easily reproduced</em>.</p>

<p>Domino can&apos;t solve the problem of poor documentation and communication, but it does make sure that any analysis run in its platform is dockerized and easy to launch in the near future. The take home from this should be that if a scientist doesn&apos;t want to read your Rmd or PDF, you can condense your language and verbosity so much, but maybe they just don&apos;t respect the quality of your research. <em>If you don&apos;t document your code or follow software development best practices for your language or declare explicit dependencies, you probably need to look at your developer habits</em>. If you can and often do create reports that summarize findings, <b>literate programming is a strong tool to make reports contain the minimum amount of code to reproduce an analysis</b> and lead other computational scientists forwards in similar modeling strategies with publication-quality graphics and document structure.</p>

<p>In the data munging subfield of data science, there is always a huge amount of under-structured data that we struggle to coerce into tabular formats for modeling and inference. Even in those tabular formats, sometimes considerable manipulation may be required to properly analyze subsets or groupings of the data. In the Python world Pandas, numpy/scipy, biopython, and matplotlib come to mind. In R, tidyverse tools are nearly ubiquitous. <b>The grammar of graphics is a theoretical framework for communicating insights from data, designed for scientists to become better communicators</b>. Don&apos;t learn it because some stupid blog told you to learn it. Learn it to the level that you feel comfortable using it. Although it <em>is</em> easier to use than some other graphics or stats suites, the best part about it is the theory that guides flexibility in presentation and clarity in the description of covariates, primary variables, groupings, or graphical layers(glyph, color, fill, summary stats) that reflect those categorical or numerical covariates.</p>

<p>As for actual modeling techniques, most scientists and bioinformaticians can do hypothesis testing and basic or intermediate regression analyses. Better foundations in these areas can have a big impact on your research. Many of those can also do clustering, unsupervised learning, and principal components analysis. Fewer still understand normalization and regularization topics to the extent that we should hope for basic and intermediate data modeling tasks. Distribution fitting is considered an advanced topic. Machine learning is a toolset for those with advanced understanding of modeling topics. It's a very strong tool and Occam's razer applies. Simple models cannot be underestimated in an age that preaches machine learning and AI are the <em>only</em> future of data analyses.</p>

<p>Just as much as we lament datasets produced from the laboratory that are under-characterized, under-sampled, or have unclear motives behind the covariate choices, <b>it&apos;s up to us to produce clear assumptions made in calculations, better benchmarks of speed and accuracy of our tools, and rigorous null models that justify metrics or probabilities produced from our calculators</b>. I&apos;m sure that was the best snapple-cap advice you&apos;ve ever heard of but I find the challenge so central to our field and yet often underdescribed and over-prescribed.</p>


    
